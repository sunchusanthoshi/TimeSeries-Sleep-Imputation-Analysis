{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839404f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\cis\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cis\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\cis\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9003f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\cis\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.20)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.11.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\cis\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11aafcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cis\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "### utils\n",
    "\n",
    "# coding=utf-8\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "'''Utility functions for GAIN.\n",
    "\n",
    "(1) normalization: MinMax Normalizer\n",
    "(2) renormalization: Recover the data from normalzied data\n",
    "(3) rounding: Handlecategorical variables after imputation\n",
    "(4) rmse_loss: Evaluate imputed data in terms of RMSE\n",
    "(5) xavier_init: Xavier initialization\n",
    "(6) binary_sampler: sample binary random variables\n",
    "(7) uniform_sampler: sample uniform random variables\n",
    "(8) sample_batch_index: sample random batch index\n",
    "'''\n",
    " \n",
    "# Necessary packages\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "##IF USING TF 2 use following import to still use TF < 2.0 Functionalities\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "def normalization (data, parameters=None):\n",
    "    '''\n",
    "    Normalize data in [0, 1] range.\n",
    "\n",
    "    Args:\n",
    "    - data: original data\n",
    "\n",
    "    Returns:\n",
    "    - norm_data: normalized data\n",
    "    - norm_parameters: min_val, max_val for each feature for renormalization\n",
    "    '''\n",
    "    \n",
    "    # Parameters\n",
    "    _,dim = data.shape\n",
    "    norm_data = data.copy()\n",
    "  \n",
    "    if parameters is None:\n",
    "  \n",
    "        # MixMax normalization\n",
    "        min_val = np.zeros(dim)\n",
    "        max_val = np.zeros(dim)\n",
    "    \n",
    "        # For each dimension\n",
    "        for i in range(dim):\n",
    "            min_val[i] = np.nanmin(norm_data[:,i])\n",
    "            norm_data[:,i] = norm_data[:,i] - np.nanmin(norm_data[:,i])\n",
    "            max_val[i] = np.nanmax(norm_data[:,i])\n",
    "            norm_data[:,i] = norm_data[:,i] / (np.nanmax(norm_data[:,i]) + 1e-6)   \n",
    "      \n",
    "        # Return norm_parameters for renormalization\n",
    "        norm_parameters = {'min_val': min_val,\n",
    "                       'max_val': max_val}\n",
    "\n",
    "    else:\n",
    "        min_val = parameters['min_val']\n",
    "        max_val = parameters['max_val']\n",
    "    \n",
    "        # For each dimension\n",
    "        for i in range(dim):\n",
    "            norm_data[:,i] = norm_data[:,i] - min_val[i]\n",
    "            norm_data[:,i] = norm_data[:,i] / (max_val[i] + 1e-6)  \n",
    "      \n",
    "        norm_parameters = parameters    \n",
    "      \n",
    "    return norm_data, norm_parameters\n",
    "\n",
    "\n",
    "def renormalization (norm_data, norm_parameters):\n",
    "    '''\n",
    "    Renormalize data from [0, 1] range to the original range.\n",
    "\n",
    "    Args:\n",
    "    - norm_data: normalized data\n",
    "    - norm_parameters: min_val, max_val for each feature for renormalization\n",
    "\n",
    "    Returns:\n",
    "    - renorm_data: renormalized original data\n",
    "    '''\n",
    "    min_val = norm_parameters['min_val']\n",
    "    max_val = norm_parameters['max_val']\n",
    "\n",
    "    _, dim = norm_data.shape\n",
    "    renorm_data = norm_data.copy()\n",
    "    \n",
    "    for i in range(dim):\n",
    "        renorm_data[:,i] = renorm_data[:,i] * (max_val[i] + 1e-6)   \n",
    "        renorm_data[:,i] = renorm_data[:,i] + min_val[i]\n",
    "    \n",
    "    return renorm_data\n",
    "\n",
    "\n",
    "def rounding (imputed_data, data_x):\n",
    "    '''\n",
    "    Round imputed data for categorical variables.\n",
    "\n",
    "    Args:\n",
    "    - imputed_data: imputed data\n",
    "    - data_x: original data with missing values\n",
    "\n",
    "    Returns:\n",
    "    - rounded_data: rounded imputed data\n",
    "    '''\n",
    "  \n",
    "    _, dim = data_x.shape\n",
    "    rounded_data = imputed_data.copy()\n",
    "  \n",
    "    for i in range(dim):\n",
    "        temp = data_x[~np.isnan(data_x[:, i]), i]\n",
    "        # Only for the categorical variable\n",
    "        if len(np.unique(temp)) < 20:\n",
    "            rounded_data[:, i] = np.round(rounded_data[:, i])\n",
    "      \n",
    "    return rounded_data\n",
    "\n",
    "\n",
    "def rmse_loss (ori_data, imputed_data, data_m):\n",
    "    '''\n",
    "    Compute RMSE loss between ori_data and imputed_data\n",
    "\n",
    "    Args:\n",
    "    - ori_data: original data without missing values\n",
    "    - imputed_data: imputed data\n",
    "    - data_m: indicator matrix for missingness\n",
    "\n",
    "    Returns:\n",
    "    - rmse: Root Mean Squared Error\n",
    "    '''\n",
    "  \n",
    "    ori_data, norm_parameters = normalization(ori_data)\n",
    "    imputed_data, _ = normalization(imputed_data, norm_parameters)\n",
    "    \n",
    "    # Only for missing values\n",
    "    nominator = np.sum(((1-data_m) * ori_data - (1-data_m) * imputed_data)**2)\n",
    "    denominator = np.sum(1-data_m)\n",
    "  \n",
    "    rmse = np.sqrt(nominator/float(denominator))\n",
    "  \n",
    "    return rmse\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    '''\n",
    "    Xavier initialization.\n",
    "    Args:\n",
    "    - size: vector size\n",
    "\n",
    "    Returns:\n",
    "    - initialized random vector.\n",
    "    '''\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "      \n",
    "\n",
    "def binary_sampler(p, rows, cols):\n",
    "    '''\n",
    "    Sample binary random variables.\n",
    "\n",
    "    Args:\n",
    "    - p: probability of 1\n",
    "    - rows: the number of rows\n",
    "    - cols: the number of columns\n",
    "\n",
    "    Returns:\n",
    "    - binary_random_matrix: generated binary random matrix.\n",
    "    '''\n",
    "    unif_random_matrix = np.random.uniform(0., 1., size = [rows, cols])\n",
    "    binary_random_matrix = 1*(unif_random_matrix < p)\n",
    "    return binary_random_matrix\n",
    "\n",
    "\n",
    "def uniform_sampler(low, high, rows, cols):\n",
    "    '''\n",
    "    Sample uniform random variables.\n",
    "\n",
    "    Args:\n",
    "    - low: low limit\n",
    "    - high: high limit\n",
    "    - rows: the number of rows\n",
    "    - cols: the number of columns\n",
    "\n",
    "    Returns:\n",
    "    - uniform_random_matrix: generated uniform random matrix.\n",
    "    '''\n",
    "    return np.random.uniform(low, high, size = [rows, cols])       \n",
    "\n",
    "\n",
    "def sample_batch_index(total, batch_size):\n",
    "    '''\n",
    "    Sample index of the mini-batch.\n",
    "\n",
    "    Args:\n",
    "    - total: total number of samples\n",
    "    - batch_size: batch size\n",
    "\n",
    "    Returns:\n",
    "    - batch_idx: batch index\n",
    "    '''\n",
    "    total_idx = np.random.permutation(total)\n",
    "    batch_idx = total_idx[:batch_size]\n",
    "    return batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a955cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "'''GAIN function.\n",
    "Date: 2020/02/28\n",
    "Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data \n",
    "           Imputation using Generative Adversarial Nets,\" ICML, 2018.\n",
    "Paper Link: http://proceedings.mlr.press/v80/yoon18a/yoon18a.pdf\n",
    "Contact: jsyoon0823@gmail.com\n",
    "'''\n",
    "\n",
    "# Necessary packages\n",
    "#import tensorflow as tf\n",
    "##IF USING TF 2 use following import to still use TF < 2.0 Functionalities\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from utils import normalization, renormalization, rounding\n",
    "# from utils import xavier_init\n",
    "# from utils import binary_sampler, uniform_sampler, sample_batch_index\n",
    "\n",
    "\n",
    "d_loss=[]\n",
    "g_loss=[]\n",
    "\n",
    "def gain (data_x, gain_parameters):\n",
    "    '''\n",
    "    Impute missing values in data_x\n",
    "\n",
    "    Args:\n",
    "    - data_x: original data with missing values\n",
    "    - gain_parameters: GAIN network parameters:\n",
    "      - batch_size: Batch size\n",
    "      - hint_rate: Hint rate\n",
    "      - alpha: Hyperparameter\n",
    "      - iterations: Iterations\n",
    "\n",
    "    Returns:\n",
    "    - imputed_data: imputed data\n",
    "    '''\n",
    "    # Define mask matrix\n",
    "    data_m = 1-np.isnan(data_x)\n",
    "  \n",
    "    # System parameters\n",
    "    batch_size = gain_parameters['batch_size']\n",
    "    hint_rate = gain_parameters['hint_rate']\n",
    "    alpha = gain_parameters['alpha']\n",
    "    iterations = gain_parameters['iterations']\n",
    "  \n",
    "    # Other parameters\n",
    "    no, dim = data_x.shape\n",
    "  \n",
    "    # Hidden state dimensions\n",
    "    h_dim = int(dim)\n",
    "  \n",
    "    # Normalization\n",
    "    norm_data, norm_parameters = normalization(data_x)\n",
    "    norm_data_x = np.nan_to_num(norm_data, 0)\n",
    "  \n",
    "    ## GAIN architecture   \n",
    "    # Input placeholders\n",
    "    # Data vector\n",
    "    X = tf.placeholder(tf.float32, shape = [None, dim])\n",
    "    # Mask vector \n",
    "    M = tf.placeholder(tf.float32, shape = [None, dim])\n",
    "    # Hint vector\n",
    "    H = tf.placeholder(tf.float32, shape = [None, dim])\n",
    "  \n",
    "    # Discriminator variables\n",
    "    D_W1 = tf.Variable(xavier_init([dim*2, h_dim])) # Data + Hint as inputs\n",
    "    D_b1 = tf.Variable(tf.zeros(shape = [h_dim]))\n",
    "  \n",
    "    D_W2 = tf.Variable(xavier_init([h_dim, h_dim]))\n",
    "    D_b2 = tf.Variable(tf.zeros(shape = [h_dim]))\n",
    "  \n",
    "    D_W3 = tf.Variable(xavier_init([h_dim, dim]))\n",
    "    D_b3 = tf.Variable(tf.zeros(shape = [dim]))  # Multi-variate outputs\n",
    "  \n",
    "    theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "  \n",
    "  #Generator variables\n",
    "  # Data + Mask as inputs (Random noise is in missing components)\n",
    "    G_W1 = tf.Variable(xavier_init([dim*2, h_dim]))  \n",
    "    G_b1 = tf.Variable(tf.zeros(shape = [h_dim]))\n",
    "  \n",
    "    G_W2 = tf.Variable(xavier_init([h_dim, h_dim]))\n",
    "    G_b2 = tf.Variable(tf.zeros(shape = [h_dim]))\n",
    "  \n",
    "    G_W3 = tf.Variable(xavier_init([h_dim, dim]))\n",
    "    G_b3 = tf.Variable(tf.zeros(shape = [dim]))\n",
    "  \n",
    "    theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "  \n",
    "  ## GAIN functions\n",
    "  # Generator\n",
    "    def generator(x,m):\n",
    "        # Concatenate Mask and Data\n",
    "        inputs = tf.concat(values = [x, m], axis = 1) \n",
    "        G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
    "        G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)   \n",
    "        # MinMax normalized output\n",
    "        G_prob = tf.nn.sigmoid(tf.matmul(G_h2, G_W3) + G_b3) \n",
    "        return G_prob\n",
    "      \n",
    "    # Discriminator\n",
    "    def discriminator(x, h):\n",
    "        # Concatenate Data and Hint\n",
    "        inputs = tf.concat(values = [x, h], axis = 1) \n",
    "        D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)  \n",
    "        D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n",
    "        D_logit = tf.matmul(D_h2, D_W3) + D_b3\n",
    "        D_prob = tf.nn.sigmoid(D_logit)\n",
    "        return D_prob\n",
    "  \n",
    "    ## GAIN structure\n",
    "    # Generator\n",
    "    G_sample = generator(X, M)\n",
    " \n",
    "    # Combine with observed data\n",
    "    Hat_X = X * M + G_sample * (1-M)\n",
    "  \n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_X, H)\n",
    "  \n",
    "    ## GAIN loss\n",
    "    D_loss_temp = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) \\\n",
    "                                + (1-M) * tf.log(1. - D_prob + 1e-8)) \n",
    "  \n",
    "    G_loss_temp = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8))\n",
    "  \n",
    "    MSE_loss = tf.reduce_mean((M * X - M * G_sample)**2) / tf.reduce_mean(M)\n",
    "  \n",
    "    D_loss = D_loss_temp\n",
    "    G_loss = G_loss_temp + alpha * MSE_loss \n",
    "  \n",
    "    ## GAIN solver\n",
    "    D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "    G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "  \n",
    "    ## Iterations\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    # Start Iterations\n",
    "    for it in tqdm(range(iterations)):    \n",
    "      \n",
    "        # Sample batch\n",
    "        batch_idx = sample_batch_index(no, batch_size)\n",
    "        X_mb = norm_data_x[batch_idx, :]  \n",
    "        M_mb = data_m[batch_idx, :]  \n",
    "        # Sample random vectors  \n",
    "        Z_mb = uniform_sampler(0, 0.01, batch_size, dim) \n",
    "        # Sample hint vectors\n",
    "        H_mb_temp = binary_sampler(hint_rate, batch_size, dim)\n",
    "        H_mb = M_mb * H_mb_temp\n",
    "      \n",
    "        # Combine random vectors with observed vectors\n",
    "        X_mb = M_mb * X_mb + (1-M_mb) * Z_mb \n",
    "      \n",
    "        _, D_loss_curr = sess.run([D_solver, D_loss_temp], \n",
    "                              feed_dict = {M: M_mb, X: X_mb, H: H_mb})\n",
    "        _, G_loss_curr, MSE_loss_curr = sess.run([G_solver, G_loss_temp, MSE_loss],\n",
    "             feed_dict = {X: X_mb, M: M_mb, H: H_mb})\n",
    "        d_loss.append(D_loss_curr)\n",
    "        g_loss.append(G_loss_curr)\n",
    "            \n",
    "        ## Return imputed data      \n",
    "        Z_mb = uniform_sampler(0, 0.01, no, dim) \n",
    "        M_mb = data_m\n",
    "        X_mb = norm_data_x          \n",
    "        X_mb = M_mb * X_mb + (1-M_mb) * Z_mb \n",
    "      \n",
    "        imputed_data = sess.run([G_sample], feed_dict = {X: X_mb, M: M_mb})[0]\n",
    "  \n",
    "        imputed_data = data_m * norm_data_x + (1-data_m) * imputed_data\n",
    "  \n",
    "        # Renormalization\n",
    "        imputed_data = renormalization(imputed_data, norm_parameters)  \n",
    "  \n",
    "        # Rounding\n",
    "        imputed_data = rounding(imputed_data, data_x)\n",
    "    \n",
    "    d_loss_df=pd.DataFrame(d_loss)\n",
    "    g_loss_df=pd.DataFrame(g_loss)\n",
    "    \n",
    "#     d_loss_df.to_csv(f'parquet/20/d_loss.csv')\n",
    "#     g_loss_df.to_csv(f'parquet/20/g_loss.csv')\n",
    "#     d_loss_df.to_csv('parquet/50/d_loss.csv')\n",
    "#     g_loss_df.to_csv('parquet/50/g_loss.csv')\n",
    "    d_loss_df.to_csv('parquet/80/d_loss.csv')\n",
    "    g_loss_df.to_csv('parquet/80/g_loss.csv')\n",
    "    \n",
    "          \n",
    "    return imputed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1b61d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def create_mask_dataset(data_x,miss_rate):\n",
    "    rows,columns=data_x.shape\n",
    "    # Set the percentage of 0s and 1s\n",
    "    percent_zeros = miss_rate/100\n",
    "    percent_ones = 1 - percent_zeros\n",
    "\n",
    "    # Generate a random array with 0s and 1s based on the specified percentages\n",
    "    result_array = np.random.choice([0, 1], size=(rows, columns), p=[percent_zeros, percent_ones])\n",
    "    \n",
    "    return result_array\n",
    "    \n",
    "\n",
    "def data_loader(data_name, miss_rate):\n",
    "    ## Load data\n",
    "    df_par=pd.read_parquet('dataset.parquet')\n",
    "    ### We need to select columns\n",
    "    df_class=df_par['sleeping']\n",
    "    data_label=df_class.to_numpy()\n",
    "    \n",
    "    df_par=df_par[['step','year','month','day','hour','minute','anglez','enmo']]\n",
    "    data_x=df_par.to_numpy()\n",
    "\n",
    "    ##Parameters\n",
    "    no, dim = data_x.shape\n",
    "\n",
    "    ##Introducing missing data\n",
    "    data_m=create_mask_dataset(data_x,miss_rate)\n",
    "    miss_data_x=data_x.copy()\n",
    "    miss_data_x[data_m==0] = np.nan\n",
    "    \n",
    "    \n",
    "\n",
    "    return data_x,miss_data_x,data_m,data_label\n",
    "\n",
    "    \n",
    "data_name='child_sleep'   \n",
    "miss_rate=80 ## CHANGE THIS FOR OTHER RATES\n",
    "### Step 1: Preparing Data and Loading Data\n",
    "ori_data_x,missing_data_x,data_m,data_label=data_loader('child_sleep',miss_rate)\n",
    "\n",
    "## Storing as Pandas DataFrame \n",
    "columns=['step', 'year','month','day', 'hour','minute','anglez', 'enmo']\n",
    "ori_df=pd.DataFrame(ori_data_x, columns=columns)\n",
    "missing_df=pd.DataFrame(missing_data_x, columns=columns)\n",
    "mask_df=pd.DataFrame(data_m, columns=columns)\n",
    "label_df=pd.DataFrame(data_label, columns=['sleeping'])\n",
    "\n",
    "# ## Saving as parquet file\n",
    "\n",
    "# if miss_rate==20:\n",
    "#     ori_df.to_parquet(r'parquet/20/original_data_X.parquet')\n",
    "#     missing_df.to_parquet(r'parquet/20/missing_data_X.parquet')\n",
    "#     mask_df.to_parquet(r'parquet/20/mask_data_X.parquet')\n",
    "#     label_df.to_parquet(r'parquet/20/label_data.parquet')\n",
    "# if miss_rate==50:\n",
    "#     ori_df.to_parquet(r'parquet/50/original_data_X.parquet')\n",
    "#     missing_df.to_parquet(r'parquet/50/missing_data_X.parquet')\n",
    "#     mask_df.to_parquet(r'parquet/50/mask_data_X.parquet')\n",
    "#     label_df.to_parquet(r'parquet/50/label_data.parquet')\n",
    "# if miss_rate==80:\n",
    "#     ori_df.to_parquet(r'parquet/20/original_data_X.parquet')\n",
    "#     missing_df.to_parquet(r'parquet/20/missing_data_X.parquet')\n",
    "#     mask_df.to_parquet(r'parquet/20/mask_data_X.parquet')\n",
    "#     label_df.to_parquet(r'parquet/20/label_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dc0e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def main(data_name,miss_rate, batch_size, hint_rate, alpha, iterations):\n",
    "\n",
    "    data_name=data_name    \n",
    "    miss_rate=miss_rate\n",
    "    \n",
    "    gain_parameters = {'batch_size': batch_size,\n",
    "                     'hint_rate': hint_rate,\n",
    "                     'alpha': alpha,\n",
    "                     'iterations': iterations}\n",
    "    \n",
    "    columns=['step', 'year','month','day', 'hour','minute','anglez', 'enmo']\n",
    "            \n",
    "    ### Step 2: Split dataset\n",
    "\n",
    "    # Specify the number of samples for training\n",
    "    num_training_samples = int((1-(miss_rate/100))*len(ori_data_x))\n",
    "    \n",
    "    # Split the indices without shuffling\n",
    "    training_idx, test_idx = np.arange(num_training_samples), np.arange(num_training_samples, ori_data_x.shape[0])\n",
    "    \n",
    "    # Use the indices to create training and test sets and also training missing and test missing\n",
    "    train_ori_data_X, test_ori_data_X = ori_data_x[training_idx, :], ori_data_x[test_idx, :]\n",
    "    train_miss_data_X, test_miss_data_X= missing_data_x[training_idx,:],missing_data_x[test_idx,:]\n",
    "    train_data_m, test_data_m=data_m[training_idx,:], data_m[test_idx,:]\n",
    "\n",
    "    labels_array=label_df.to_numpy()\n",
    "    train_label,test_label=labels_array[training_idx],labels_array[test_idx]\n",
    "    \n",
    "    \n",
    "    ##### SAVE Training Dataset, Test Dataset, missing training set and missing test set for bfill and ffill imputation. \n",
    "    train_x_df=pd.DataFrame(train_ori_data_X)\n",
    "    train_x_df.to_parquet(f'parquet/{miss_rate}/train_x.parquet')\n",
    "    test_x_df=pd.DataFrame(test_ori_data_X)\n",
    "    test_x_df.to_parquet(f'parquet/{miss_rate}/test_x.parquet')\n",
    "    train_miss_x_df=pd.DataFrame(train_miss_data_X)\n",
    "    train_miss_x_df.to_parquet(f'parquet/{miss_rate}/train_miss_x.parquet')\n",
    "    test_miss_x_df=pd.DataFrame(test_miss_data_X)\n",
    "    test_miss_x_df.to_parquet(f'parquet/{miss_rate}/test_miss_x.parquet')\n",
    "    train_label_df=pd.DataFrame(train_label)\n",
    "    train_label_df.to_parquet(f'parquet/{miss_rate}/train_y.parquet')\n",
    "    test_label_df=pd.DataFrame(test_label)\n",
    "    test_label_df.to_parquet(f'parquet/{miss_rate}/test_y.parquet')\n",
    "    \n",
    "    \n",
    "    x_train=train_ori_data_X\n",
    "    x_test=test_ori_data_X\n",
    "    y_train=labels_array[training_idx]\n",
    "    y_test= labels_array[test_idx]\n",
    "    \n",
    "\n",
    "    test_label_imputed_classfication_df=pd.DataFrame(y_test, columns = ['sleeping'])\n",
    "\n",
    "    \n",
    "    x_test_complete_data=pd.DataFrame(x_test,columns=['step', 'year','month','day', 'hour','minute','anglez', 'enmo'])\n",
    "    x_test_complete_label=y_test\n",
    "    \n",
    "    \n",
    "    ## KNN Classfier trained on complete training data (no missing values)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "    neigh.fit(x_train, np.ravel(y_train,order='C'))\n",
    "    \n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    y_train_pred = neigh.predict(x_train)\n",
    "\n",
    "    # Calculate accuracy on the training data\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(f\"Train Accuracy on KNN: {train_accuracy}\")\n",
    "    \n",
    "    ## XGB Classfier trained on complete training data (no missing values)\n",
    "    xgb_model=xgb.XGBClassifier(objective='binary:logistic')\n",
    "    xgb_model.fit(x_train,y_train)\n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "    # Calculate accuracy on the training data\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(f\"Train Accuracy on XGB: {train_accuracy}\")\n",
    "\n",
    "    #Impute missing data for training split\n",
    "    train_imputed_data_X = gain(missing_data_x[training_idx,:], gain_parameters) \n",
    "\n",
    "    # Report the RMSE performance\n",
    "    rmse = rmse_loss (x_train, train_imputed_data_X, train_data_m) \n",
    "\n",
    "    ##Store rmse for training split    \n",
    "    rmse_train=rmse\n",
    "    print('train_rmse',rmse_train)\n",
    "\n",
    "    #Impute missing data for test split\n",
    "    test_imputed_data_X = gain(test_miss_data_X, gain_parameters)\n",
    "    \n",
    "     # Report the RMSE performance\n",
    "    rmse_test = rmse_loss(x_test, test_imputed_data_X, test_data_m)\n",
    "    \n",
    "    ## to imputed with ffill and bfill, we need to convert ndarray to pandas Dataframe. Save as parquet file\n",
    "    test_miss_data_X_df=pd.DataFrame(test_miss_data_X)\n",
    "    \n",
    "#     ### ************* DEBUG************##############\n",
    "#     print(test_miss_data_X_df.isnull().sum())\n",
    "#     print(\"Before forward fill:\", test_miss_data_X_df.shape)\n",
    "#     test_imputed_data_X_ffill = test_miss_data_X_df.fillna(method='ffill')\n",
    "#     print(\"After forward fill:\", test_imputed_data_X_ffill.shape)\n",
    "    \n",
    "#     print(test_imputed_data_X_ffill)\n",
    "    \n",
    "#     test_imputed_data_X_bfill=test_miss_data_X_df.fillna(method='bfill')\n",
    "    \n",
    "    #ori_data_x er jaygay test_X, data_m er jaygay test_M\n",
    "#     rmse_ffill=rmse_loss(test_ori_data_X, test_imputed_data_X_ffill.to_numpy(), test_data_m)\n",
    "#     rmse_bfill=rmse_loss(test_ori_data_X, test_imputed_data_X_bfill.to_numpy(), test_data_m)\n",
    "\n",
    "    # Impute missing data\n",
    "\n",
    "    if miss_rate==20:\n",
    "        test_imputed_data_X.tofile(f'parquet/{miss_rate}/test_imputed_data_X.parquet')\n",
    "    if miss_rate==50:\n",
    "        test_imputed_data_X.tofile(f'parquet/{miss_rate}/test_imputed_data_X.parquet')\n",
    "    if miss_rate==80:\n",
    "        test_imputed_data_X.tofile(f'parquet/{miss_rate}/test_imputed_data_X.parquet')\n",
    "    \n",
    "    \n",
    "    test_dataframe_data_imputed_read=pd.DataFrame(test_imputed_data_X)\n",
    "    \n",
    "\n",
    "    print('\\n')\n",
    "    print('Train RMSE Performance: ' + str(np.around(rmse_train, 4)))\n",
    "    print('Test RMSE Performance GAIN : ' + str(np.around(rmse_test, 4)))\n",
    "#     print('Test RMSE Performance ffill : ' + str(np.around(rmse_ffill, 4)))\n",
    "#     print('Test RMSE Performance bfill : ' + str(np.around(rmse_bfill, 4)))\n",
    "    \n",
    "\n",
    "\n",
    "    ####CLASSIFICATION TASK: PREPARE TEST DATA ##################\n",
    "\n",
    "    #STEP 1: append x_test with y_test \n",
    "    imputed_test_set = pd.concat([test_dataframe_data_imputed_read, pd.DataFrame(test_label)], axis=1, ignore_index=True)\n",
    "#     print(imputed_test_set.shape)\n",
    "#     imputed_test_set_ffill = pd.concat([test_imputed_data_X_ffill, pd.DataFrame(test_label)], axis=1, ignore_index=True)\n",
    "#     print(imputed_test_set_ffill.shape)\n",
    "#     imputed_test_set_bfill = pd.concat([test_imputed_data_X_bfill, pd.DataFrame(test_label)], axis=1, ignore_index=True)\n",
    "#     print(imputed_test_set_bfill.shape)\n",
    "    complete_test_set=pd.concat([ x_test_complete_data, pd.DataFrame(test_label)], axis=1, ignore_index=True)\n",
    "#     print(complete_test_set.shape)\n",
    "    ##append###\n",
    "    full_test_set = pd.concat([imputed_test_set,complete_test_set])\n",
    "#     print(full_test_set.shape)\n",
    "    \n",
    "#     full_test_set_ffill = pd.concat([imputed_test_set_ffill,complete_test_set])\n",
    "#     print(full_test_set_ffill.shape)\n",
    "    \n",
    "#     full_test_set_bfill = pd.concat([imputed_test_set_bfill,complete_test_set])\n",
    "#     print(full_test_set_bfill.shape)\n",
    "\n",
    " \n",
    "    full_test_set.to_csv(f'parquet/{miss_rate}/test_data.csv')\n",
    "    full_test_x=full_test_set.iloc[:,:-1]\n",
    "#     full_test_x_ffill=full_test_set_ffill.iloc[:,:-1]\n",
    "#     full_test_x_bfill=full_test_set_bfill.iloc[:,:-1]\n",
    "#     print('full_test_x len')\n",
    "#     print(full_test_x.shape)\n",
    "    \n",
    "    full_test_y=full_test_set.iloc[:,-1] # last column of data frame (sleeping)\n",
    "#     print(full_test_y.shape)\n",
    "#     full_test_y_ffill=full_test_set_ffill.iloc[:,-1] # last column of data frame (sleeping)\n",
    "#     print(full_test_y_ffill.shape)\n",
    "#     full_test_y_bfill=full_test_set_bfill.iloc[:,-1] # last column of data frame (sleeping)\n",
    "#     print(full_test_y_bfill.shape)\n",
    "    \n",
    "\n",
    "    print('\\nKNN Classification')\n",
    "    print('Classification Report:')\n",
    "    \n",
    "    \n",
    "    predictions_knn = neigh.predict(full_test_x)\n",
    "#     predictions_knn_fill = neigh.predict(full_test_x_ffill)\n",
    "#     predictions_knn_bfill = neigh.predict(full_test_x_bfill)\n",
    "    \n",
    "    print(classification_report(full_test_y, predictions_knn))\n",
    "#     print(classification_report(full_test_y_ffill, predictions_knn_ffill))\n",
    "#     print(classification_report(full_test_y_bfill, predictions_knn_bfill))\n",
    "    print('\\n')\n",
    "    print(\"Accuracy Score of KNN Classifier: \")\n",
    "    \n",
    "    acc_knn = accuracy_score(full_test_y, predictions_knn)\n",
    "#     acc_knn_ffill = accuracy_score(full_test_y_bfill, predictions_knn_ffill)\n",
    "#     acc_knn_bfill = accuracy_score(full_test_y_ffill, predictions_knn_bfill)\n",
    "    print(acc_knn)\n",
    "#     print(acc_knn_ffill)\n",
    "#     print(acc_knn_bfill)\n",
    "    print('\\n')\n",
    "    \n",
    "    print('\\nXGB Classification')\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "    # Calculate accuracy on the training data\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "    predictions_xgb=xgb_model.predict(full_test_x)\n",
    "#     predictions_xgb_ffill=xgb_model.predict(full_test_x_ffill)\n",
    "#     predictions_xgb_bfill=xgb_model.predict(full_test_x_bfill)\n",
    "    print(classification_report(full_test_y, predictions_xgb))\n",
    "#     print(classification_report(full_test_y_ffill, predictions_xgb_ffill))\n",
    "#     print(classification_report(full_test_y_bfill, predictions_xgb_bfill))\n",
    "    print('\\n')\n",
    "    print(\"Accuracy Score of XGB Classifier: \")\n",
    "    acc_xgb = accuracy_score(full_test_y, predictions_xgb)\n",
    "#     acc_xgb_ffill = accuracy_score(full_test_y_ffill, predictions_xgb_ffill)\n",
    "#     acc_xgb_bfill = accuracy_score(full_test_y_bfill, predictions_xgb_bfill)\n",
    "    print(acc_xgb)\n",
    "#     print(acc_xgb_ffill)\n",
    "#     print(acc_xgb_bfill)\n",
    "    print('\\n')\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8081cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy on KNN: 0.9590118080810843\n",
      "Train Accuracy on XGB: 0.9326885829391229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [2:34:44<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse 0.2772557404581131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [37:51<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train RMSE Performance: 0.2773\n",
      "Test RMSE Performance GAIN : 0.2897\n",
      "\n",
      "KNN Classification\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.66      0.58   2786568\n",
      "           1       0.45      0.31      0.37   2479656\n",
      "\n",
      "    accuracy                           0.50   5266224\n",
      "   macro avg       0.48      0.49      0.47   5266224\n",
      "weighted avg       0.49      0.50      0.48   5266224\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of KNN Classifier: \n",
      "0.49583078881566756\n",
      "\n",
      "\n",
      "\n",
      "XGB Classification\n",
      "Train Accuracy: 0.9326885829391229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.64      0.57   2786568\n",
      "           1       0.44      0.32      0.37   2479656\n",
      "\n",
      "    accuracy                           0.49   5266224\n",
      "   macro avg       0.48      0.48      0.47   5266224\n",
      "weighted avg       0.48      0.49      0.48   5266224\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of XGB Classifier: \n",
      "0.4884089624748207\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## arguments of main: dataset_name, miss_rate, batch_size, hint_rate, alpha, iterations\n",
    "rmse=main('child_sleep', 20, 128, 0.9, 100, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d9f18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy on KNN: 0.9722030813729154\n",
      "Train Accuracy on XGB: 0.9727268722333118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [1:37:18<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse 0.27054536546091384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [1:37:14<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train RMSE Performance: 0.2705\n",
      "Test RMSE Performance GAIN : 0.2843\n",
      "\n",
      "KNN Classification\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64   7924560\n",
      "           1       0.40      0.32      0.35   5241000\n",
      "\n",
      "    accuracy                           0.54  13165560\n",
      "   macro avg       0.50      0.50      0.50  13165560\n",
      "weighted avg       0.52      0.54      0.52  13165560\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of KNN Classifier: \n",
      "0.5358075159734945\n",
      "\n",
      "\n",
      "\n",
      "XGB Classification\n",
      "Train Accuracy: 0.9727268722333118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.66   7924560\n",
      "           1       0.43      0.33      0.37   5241000\n",
      "\n",
      "    accuracy                           0.56  13165560\n",
      "   macro avg       0.52      0.52      0.51  13165560\n",
      "weighted avg       0.54      0.56      0.54  13165560\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of XGB Classifier: \n",
      "0.5559610833113061\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############### CHANGE filepath in GAIN g_loss and d_loss\n",
    "\n",
    "## arguments of main: dataset_name, miss_rate, batch_size, hint_rate, alpha, iterations\n",
    "rmse=main('child_sleep', 50, 128, 0.9, 100, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e5254ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy on KNN: 0.9780540964661194\n",
      "Train Accuracy on XGB: 0.9924970880452818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [30:21<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse 0.403437994069898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1500/1500 [2:01:36<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train RMSE Performance: 0.4034\n",
      "Test RMSE Performance GAIN : 0.4013\n",
      "\n",
      "KNN Classification\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65  12932738\n",
      "           1       0.39      0.32      0.35   8132160\n",
      "\n",
      "    accuracy                           0.55  21064898\n",
      "   macro avg       0.50      0.50      0.50  21064898\n",
      "weighted avg       0.53      0.55      0.54  21064898\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of KNN Classifier: \n",
      "0.5454763179959381\n",
      "\n",
      "\n",
      "\n",
      "XGB Classification\n",
      "Train Accuracy: 0.9924970880452818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70  12932738\n",
      "           1       0.41      0.20      0.27   8132160\n",
      "\n",
      "    accuracy                           0.58  21064898\n",
      "   macro avg       0.51      0.51      0.49  21064898\n",
      "weighted avg       0.54      0.58      0.54  21064898\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score of XGB Classifier: \n",
      "0.5784416805626118\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############## CHANGE filepath in GAIN g_loss and d_loss\n",
    "\n",
    "## arguments of main: dataset_name, miss_rate, batch_size, hint_rate, alpha, iterations\n",
    "rmse=main('child_sleep', 80, 128, 0.9, 100, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fd74f",
   "metadata": {},
   "source": [
    "## Forward Fill, Backward Fill Imputation on 20%, 50%, 80% missing data on KNN, XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45b7b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss (ori_data, imputed_data, data_m):\n",
    "    '''\n",
    "    Compute RMSE loss between ori_data and imputed_data\n",
    "\n",
    "    Args:\n",
    "    - ori_data: original data without missing values\n",
    "    - imputed_data: imputed data\n",
    "    - data_m: indicator matrix for missingness\n",
    "\n",
    "    Returns:\n",
    "    - rmse: Root Mean Squared Error\n",
    "    '''\n",
    "    def has_nan(array):\n",
    "        return np.any(np.isnan(array))\n",
    "    \n",
    "#     print(has_nan(ori_data))\n",
    "#     print(has_nan(imputed_data))\n",
    "#     print(has_nan(data_m))\n",
    "    \n",
    "    ori_data, norm_parameters = normalization(ori_data)\n",
    "    imputed_data, _ = normalization(imputed_data, norm_parameters)\n",
    "    \n",
    "    # Only for missing values\n",
    "    nominator = np.sum(((1-data_m) * ori_data - (1-data_m) * imputed_data)**2)\n",
    "    denominator = np.sum(1-data_m)\n",
    "  \n",
    "    rmse = np.sqrt(nominator/float(denominator))\n",
    "#     print(rmse)\n",
    "  \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6f50a73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:47: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:66: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_ffill\n",
      "0.05235069069783292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2072679760.py:73: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_bfill\n",
      "0.052138546123293904\n",
      "ACCURACY CALCULATION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87  12932738\n",
      "           1       0.83      0.73      0.78   8132160\n",
      "\n",
      "    accuracy                           0.84  21064898\n",
      "   macro avg       0.84      0.82      0.83  21064898\n",
      "weighted avg       0.84      0.84      0.84  21064898\n",
      "\n",
      "Accuracy Score of KNN Classifier (Forward Fill): \n",
      "0.8388493977041807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87  12932738\n",
      "           1       0.83      0.73      0.78   8132160\n",
      "\n",
      "    accuracy                           0.84  21064898\n",
      "   macro avg       0.84      0.82      0.83  21064898\n",
      "weighted avg       0.84      0.84      0.84  21064898\n",
      "\n",
      "Accuracy Score of KNN Classifier: (Backward Fill)\n",
      "0.8387854524621956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86  12932738\n",
      "           1       0.81      0.70      0.75   8132160\n",
      "\n",
      "    accuracy                           0.82  21064898\n",
      "   macro avg       0.82      0.80      0.80  21064898\n",
      "weighted avg       0.82      0.82      0.82  21064898\n",
      "\n",
      "Accuracy Score of XGB Classifier (Forward Fill): \n",
      "0.8199298662637721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86  12932738\n",
      "           1       0.81      0.70      0.75   8132160\n",
      "\n",
      "    accuracy                           0.82  21064898\n",
      "   macro avg       0.82      0.80      0.80  21064898\n",
      "weighted avg       0.82      0.82      0.82  21064898\n",
      "\n",
      "Accuracy Score of XGB Classifier (Backward Fill): \n",
      "0.8198817767833483\n"
     ]
    }
   ],
   "source": [
    "miss_rate=\"80\"\n",
    "\n",
    "#### read parquet file with missing test data x\n",
    "missing_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_miss_x.parquet\")\n",
    "missing_test_data=missing_test_df.to_numpy()\n",
    "### read parquet file with test (no missing) data x\n",
    "ori_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_x.parquet\")\n",
    "ori_test_data=ori_test_df.to_numpy()\n",
    "### build mask test data x\n",
    "mask_test_df = pd.notna(missing_test_df).astype(int)\n",
    "mask_test_data=mask_test_df.to_numpy()\n",
    "\n",
    "### impute using ffill\n",
    "imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
    "# print(imputed_test_df_ffill.isnull().sum()) ## One missing value instance left\n",
    "imputed_test_data_ffill=imputed_test_df_ffill.to_numpy()\n",
    "\n",
    "### impute using bfill\n",
    "imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
    "# print(imputed_test_df_bfill.isnull().sum())\n",
    "imputed_test_data_bfill=imputed_test_df_bfill.to_numpy()\n",
    "\n",
    "\n",
    "###Note There are still missing values so we need to fill those while preparing test sets\n",
    "\n",
    "###prepare test data\n",
    "## original test data\n",
    "test_x_df=pd.read_parquet(f'parquet/{miss_rate}/test_x.parquet')\n",
    "test_y_df=pd.read_parquet(f'parquet/{miss_rate}/test_y.parquet')\n",
    "test_df=pd.concat([ test_x_df, test_y_df], axis=1, ignore_index=True)\n",
    "\n",
    "## original test+imputed test bfill\n",
    "imputed_test_set_ffill = pd.concat([imputed_test_df_ffill,test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_ffill.shape) # (2633112, 9)\n",
    "full_test_set_ffill=pd.concat([imputed_test_set_ffill,test_df])\n",
    "\n",
    "##original test+imputed test bfill\n",
    "imputed_test_set_bfill = pd.concat([imputed_test_df_bfill, test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_bfill.shape) # (2633112, 9)\n",
    "full_test_set_bfill= pd.concat([imputed_test_set_bfill,test_df])\n",
    "\n",
    "\n",
    "###### Drop rows/Impute rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_ffill.shape)\n",
    "# full_test_set_ffill=full_test_set_ffill.dropna()\n",
    "full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_ffill.shape)\n",
    "\n",
    "\n",
    "####Drop rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_bfill.shape)\n",
    "full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_bfill.shape)\n",
    "\n",
    "# print(\"Check concat dfs: label vs data\")\n",
    "# print(test_y_df.shape) # (2633112, 1)\n",
    "# print(imputed_test_df_ffill.shape) #(2633112, 8) #Has missing\n",
    "# print(imputed_test_df_bfill.shape)  #(2633112, 8)\n",
    "\n",
    "print('RMSE calculation')\n",
    "### compute rmse for ffill imputation\n",
    "imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n",
    "rmse_ffill=rmse_loss(ori_test_data, imputed_test_set_ffill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_ffill')\n",
    "print(rmse_ffill)\n",
    "\n",
    "\n",
    "### compute rmse for bfill imputation\n",
    "imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n",
    "rmse_bfill=rmse_loss(ori_test_data, imputed_test_set_bfill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_bfill')\n",
    "print(rmse_bfill)\n",
    "\n",
    "\n",
    "\n",
    "### classification task\n",
    "\n",
    "### read trainx\n",
    "train_x_df=pd.read_parquet(f\"parquet/{miss_rate}/train_x.parquet\")\n",
    "x_train=train_x_df.to_numpy()\n",
    "### read train y\n",
    "train_y_df=pd.read_parquet(f\"parquet/{miss_rate}/train_y.parquet\")\n",
    "y_train=train_y_df.to_numpy()\n",
    "\n",
    "# ## KNN Classfier trained on complete training data (no missing values)\n",
    "# neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "# neigh.fit(x_train, np.ravel(y_train,order='C'))\n",
    "    \n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = neigh.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on KNN: {train_accuracy}\")\n",
    "\n",
    "# ## XGB Classfier trained on complete training data (no missing values)\n",
    "# xgb_model=xgb.XGBClassifier(objective='binary:logistic')\n",
    "# xgb_model.fit(x_train,y_train)\n",
    "\n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on XGB: {train_accuracy}\")\n",
    "\n",
    "print('ACCURACY CALCULATION')\n",
    "\n",
    "##find acc for knn ffill\n",
    "predictions_knn_ffill = neigh.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill))\n",
    "print(\"Accuracy Score of KNN Classifier (Forward Fill): \")\n",
    "acc_knn_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill)\n",
    "\n",
    "print(acc_knn_ffill)\n",
    "\n",
    "### find acc for knn bfill\n",
    "predictions_knn_bfill = neigh.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_knn_bfill))\n",
    "print(\"Accuracy Score of KNN Classifier: (Backward Fill)\")\n",
    "acc_knn_bfill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_bfill)\n",
    "\n",
    "print(acc_knn_bfill)\n",
    "\n",
    "###find acc for xgboost ffill\n",
    "predictions_xgb_ffill=xgb_model.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill))\n",
    "print(\"Accuracy Score of XGB Classifier (Forward Fill): \")\n",
    "acc_xgb_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill)\n",
    "\n",
    "print(acc_xgb_ffill)\n",
    "\n",
    "##find acc for knn bfill\n",
    "predictions_xgb_bfill=xgb_model.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill))\n",
    "print(\"Accuracy Score of XGB Classifier (Backward Fill): \")\n",
    "acc_xgb_bfill = accuracy_score(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill)\n",
    "\n",
    "\n",
    "print(acc_xgb_bfill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc4a27df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:47: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:66: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_ffill\n",
      "0.033358506134696875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\3582167645.py:73: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_bfill\n",
      "0.03346554852162805\n",
      "ACCURACY CALCULATION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82   7924560\n",
      "           1       0.75      0.62      0.68   5241000\n",
      "\n",
      "    accuracy                           0.77  13165560\n",
      "   macro avg       0.76      0.74      0.75  13165560\n",
      "weighted avg       0.76      0.77      0.76  13165560\n",
      "\n",
      "Accuracy Score of KNN Classifier (Forward Fill): \n",
      "0.7667789292669662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82   7924560\n",
      "           1       0.75      0.62      0.68   5241000\n",
      "\n",
      "    accuracy                           0.77  13165560\n",
      "   macro avg       0.76      0.74      0.75  13165560\n",
      "weighted avg       0.77      0.77      0.76  13165560\n",
      "\n",
      "Accuracy Score of KNN Classifier: (Backward Fill)\n",
      "0.7667866007978392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80   7924560\n",
      "           1       0.72      0.59      0.65   5241000\n",
      "\n",
      "    accuracy                           0.75  13165560\n",
      "   macro avg       0.74      0.72      0.73  13165560\n",
      "weighted avg       0.74      0.75      0.74  13165560\n",
      "\n",
      "Accuracy Score of XGB Classifier (Forward Fill): \n",
      "0.7473928947952081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80   7924560\n",
      "           1       0.72      0.59      0.65   5241000\n",
      "\n",
      "    accuracy                           0.75  13165560\n",
      "   macro avg       0.74      0.72      0.73  13165560\n",
      "weighted avg       0.74      0.75      0.74  13165560\n",
      "\n",
      "Accuracy Score of XGB Classifier (Backward Fill): \n",
      "0.7473989712553055\n"
     ]
    }
   ],
   "source": [
    "miss_rate=\"50\"\n",
    "\n",
    "#### read parquet file with missing test data x\n",
    "missing_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_miss_x.parquet\")\n",
    "missing_test_data=missing_test_df.to_numpy()\n",
    "### read parquet file with test (no missing) data x\n",
    "ori_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_x.parquet\")\n",
    "ori_test_data=ori_test_df.to_numpy()\n",
    "### build mask test data x\n",
    "mask_test_df = pd.notna(missing_test_df).astype(int)\n",
    "mask_test_data=mask_test_df.to_numpy()\n",
    "\n",
    "### impute using ffill\n",
    "imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
    "# print(imputed_test_df_ffill.isnull().sum()) ## One missing value instance left\n",
    "imputed_test_data_ffill=imputed_test_df_ffill.to_numpy()\n",
    "\n",
    "### impute using bfill\n",
    "imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
    "# print(imputed_test_df_bfill.isnull().sum())\n",
    "imputed_test_data_bfill=imputed_test_df_bfill.to_numpy()\n",
    "\n",
    "\n",
    "###Note There are still missing values so we need to fill those while preparing test sets\n",
    "\n",
    "###prepare test data\n",
    "## original test data\n",
    "test_x_df=pd.read_parquet(f'parquet/{miss_rate}/test_x.parquet')\n",
    "test_y_df=pd.read_parquet(f'parquet/{miss_rate}/test_y.parquet')\n",
    "test_df=pd.concat([ test_x_df, test_y_df], axis=1, ignore_index=True)\n",
    "\n",
    "## original test+imputed test bfill\n",
    "imputed_test_set_ffill = pd.concat([imputed_test_df_ffill,test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_ffill.shape) # (2633112, 9)\n",
    "full_test_set_ffill=pd.concat([imputed_test_set_ffill,test_df])\n",
    "\n",
    "##original test+imputed test bfill\n",
    "imputed_test_set_bfill = pd.concat([imputed_test_df_bfill, test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_bfill.shape) # (2633112, 9)\n",
    "full_test_set_bfill= pd.concat([imputed_test_set_bfill,test_df])\n",
    "\n",
    "\n",
    "###### Drop rows/Impute rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_ffill.shape)\n",
    "# full_test_set_ffill=full_test_set_ffill.dropna()\n",
    "full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_ffill.shape)\n",
    "\n",
    "\n",
    "####Drop rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_bfill.shape)\n",
    "full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_bfill.shape)\n",
    "\n",
    "# print(\"Check concat dfs: label vs data\")\n",
    "# print(test_y_df.shape) # (2633112, 1)\n",
    "# print(imputed_test_df_ffill.shape) #(2633112, 8) #Has missing\n",
    "# print(imputed_test_df_bfill.shape)  #(2633112, 8)\n",
    "\n",
    "print('RMSE calculation')\n",
    "### compute rmse for ffill imputation\n",
    "imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n",
    "rmse_ffill=rmse_loss(ori_test_data, imputed_test_set_ffill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_ffill')\n",
    "print(rmse_ffill)\n",
    "\n",
    "\n",
    "### compute rmse for bfill imputation\n",
    "imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n",
    "rmse_bfill=rmse_loss(ori_test_data, imputed_test_set_bfill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_bfill')\n",
    "print(rmse_bfill)\n",
    "\n",
    "\n",
    "\n",
    "### classification task\n",
    "\n",
    "### read trainx\n",
    "train_x_df=pd.read_parquet(f\"parquet/{miss_rate}/train_x.parquet\")\n",
    "x_train=train_x_df.to_numpy()\n",
    "### read train y\n",
    "train_y_df=pd.read_parquet(f\"parquet/{miss_rate}/train_y.parquet\")\n",
    "y_train=train_y_df.to_numpy()\n",
    "\n",
    "# ## KNN Classfier trained on complete training data (no missing values)\n",
    "# neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "# neigh.fit(x_train, np.ravel(y_train,order='C'))\n",
    "    \n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = neigh.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on KNN: {train_accuracy}\")\n",
    "\n",
    "# ## XGB Classfier trained on complete training data (no missing values)\n",
    "# xgb_model=xgb.XGBClassifier(objective='binary:logistic')\n",
    "# xgb_model.fit(x_train,y_train)\n",
    "\n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on XGB: {train_accuracy}\")\n",
    "\n",
    "print('ACCURACY CALCULATION')\n",
    "\n",
    "##find acc for knn ffill\n",
    "predictions_knn_ffill = neigh.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill))\n",
    "print(\"Accuracy Score of KNN Classifier (Forward Fill): \")\n",
    "acc_knn_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill)\n",
    "\n",
    "print(acc_knn_ffill)\n",
    "\n",
    "### find acc for knn bfill\n",
    "predictions_knn_bfill = neigh.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_knn_bfill))\n",
    "print(\"Accuracy Score of KNN Classifier: (Backward Fill)\")\n",
    "acc_knn_bfill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_bfill)\n",
    "\n",
    "print(acc_knn_bfill)\n",
    "\n",
    "###find acc for xgboost ffill\n",
    "predictions_xgb_ffill=xgb_model.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill))\n",
    "print(\"Accuracy Score of XGB Classifier (Forward Fill): \")\n",
    "acc_xgb_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill)\n",
    "\n",
    "print(acc_xgb_ffill)\n",
    "\n",
    "##find acc for knn bfill\n",
    "predictions_xgb_bfill=xgb_model.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill))\n",
    "print(\"Accuracy Score of XGB Classifier (Backward Fill): \")\n",
    "acc_xgb_bfill = accuracy_score(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill)\n",
    "\n",
    "\n",
    "print(acc_xgb_bfill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f56b1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:47: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:66: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_ffill\n",
      "0.033479263288629574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cis\\AppData\\Local\\Temp\\ipykernel_60520\\2332438616.py:73: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_bfill\n",
      "0.033710399181793166\n",
      "ACCURACY CALCULATION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.66      0.58   2786568\n",
      "           1       0.45      0.30      0.36   2479656\n",
      "\n",
      "    accuracy                           0.49   5266224\n",
      "   macro avg       0.48      0.48      0.47   5266224\n",
      "weighted avg       0.48      0.49      0.48   5266224\n",
      "\n",
      "Accuracy Score of KNN Classifier (Forward Fill): \n",
      "0.49375871592245224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.66      0.58   2786568\n",
      "           1       0.45      0.31      0.36   2479656\n",
      "\n",
      "    accuracy                           0.49   5266224\n",
      "   macro avg       0.48      0.48      0.47   5266224\n",
      "weighted avg       0.48      0.49      0.48   5266224\n",
      "\n",
      "Accuracy Score of KNN Classifier: (Backward Fill)\n",
      "0.49383011432859675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57   2786568\n",
      "           1       0.43      0.29      0.35   2479656\n",
      "\n",
      "    accuracy                           0.48   5266224\n",
      "   macro avg       0.47      0.47      0.46   5266224\n",
      "weighted avg       0.47      0.48      0.47   5266224\n",
      "\n",
      "Accuracy Score of XGB Classifier (Forward Fill): \n",
      "0.48301819292153164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57   2786568\n",
      "           1       0.43      0.29      0.35   2479656\n",
      "\n",
      "    accuracy                           0.48   5266224\n",
      "   macro avg       0.47      0.47      0.46   5266224\n",
      "weighted avg       0.47      0.48      0.47   5266224\n",
      "\n",
      "Accuracy Score of XGB Classifier (Backward Fill): \n",
      "0.48300395121817835\n"
     ]
    }
   ],
   "source": [
    "miss_rate=\"20\"\n",
    "\n",
    "#### read parquet file with missing test data x\n",
    "missing_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_miss_x.parquet\")\n",
    "missing_test_data=missing_test_df.to_numpy()\n",
    "### read parquet file with test (no missing) data x\n",
    "ori_test_df=pd.read_parquet(f\"parquet/{miss_rate}/test_x.parquet\")\n",
    "ori_test_data=ori_test_df.to_numpy()\n",
    "### build mask test data x\n",
    "mask_test_df = pd.notna(missing_test_df).astype(int)\n",
    "mask_test_data=mask_test_df.to_numpy()\n",
    "\n",
    "### impute using ffill\n",
    "imputed_test_df_ffill=missing_test_df.fillna(method='ffill')\n",
    "# print(imputed_test_df_ffill.isnull().sum()) ## One missing value instance left\n",
    "imputed_test_data_ffill=imputed_test_df_ffill.to_numpy()\n",
    "\n",
    "### impute using bfill\n",
    "imputed_test_df_bfill=missing_test_df.fillna(method='bfill')\n",
    "# print(imputed_test_df_bfill.isnull().sum())\n",
    "imputed_test_data_bfill=imputed_test_df_bfill.to_numpy()\n",
    "\n",
    "\n",
    "###Note There are still missing values so we need to fill those while preparing test sets\n",
    "\n",
    "###prepare test data\n",
    "## original test data\n",
    "test_x_df=pd.read_parquet(f'parquet/{miss_rate}/test_x.parquet')\n",
    "test_y_df=pd.read_parquet(f'parquet/{miss_rate}/test_y.parquet')\n",
    "test_df=pd.concat([ test_x_df, test_y_df], axis=1, ignore_index=True)\n",
    "\n",
    "## original test+imputed test bfill\n",
    "imputed_test_set_ffill = pd.concat([imputed_test_df_ffill,test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_ffill.shape) # (2633112, 9)\n",
    "full_test_set_ffill=pd.concat([imputed_test_set_ffill,test_df])\n",
    "\n",
    "##original test+imputed test bfill\n",
    "imputed_test_set_bfill = pd.concat([imputed_test_df_bfill, test_y_df ], axis=1, ignore_index=True)\n",
    "# print(imputed_test_set_bfill.shape) # (2633112, 9)\n",
    "full_test_set_bfill= pd.concat([imputed_test_set_bfill,test_df])\n",
    "\n",
    "\n",
    "###### Drop rows/Impute rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_ffill.shape)\n",
    "# full_test_set_ffill=full_test_set_ffill.dropna()\n",
    "full_test_set_ffill=full_test_set_ffill.fillna(method='bfill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_ffill.shape)\n",
    "\n",
    "\n",
    "####Drop rows where there are Nan values\n",
    "# print('Before drop')\n",
    "# print(full_test_set_bfill.shape)\n",
    "full_test_set_bfill=full_test_set_bfill.fillna(method='ffill')\n",
    "# print(\"After drop\")\n",
    "# print(full_test_set_bfill.shape)\n",
    "\n",
    "# print(\"Check concat dfs: label vs data\")\n",
    "# print(test_y_df.shape) # (2633112, 1)\n",
    "# print(imputed_test_df_ffill.shape) #(2633112, 8) #Has missing\n",
    "# print(imputed_test_df_bfill.shape)  #(2633112, 8)\n",
    "\n",
    "print('RMSE calculation')\n",
    "### compute rmse for ffill imputation\n",
    "imputed_test_set_ffill=imputed_test_set_ffill.fillna(method='bfill')\n",
    "rmse_ffill=rmse_loss(ori_test_data, imputed_test_set_ffill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_ffill')\n",
    "print(rmse_ffill)\n",
    "\n",
    "\n",
    "### compute rmse for bfill imputation\n",
    "imputed_test_set_bfill=imputed_test_set_bfill.fillna(method='ffill')\n",
    "rmse_bfill=rmse_loss(ori_test_data, imputed_test_set_bfill.iloc[:, :-1].to_numpy(), mask_test_data)\n",
    "print('rmse_bfill')\n",
    "print(rmse_bfill)\n",
    "\n",
    "\n",
    "\n",
    "### classification task\n",
    "\n",
    "### read trainx\n",
    "train_x_df=pd.read_parquet(f\"parquet/{miss_rate}/train_x.parquet\")\n",
    "x_train=train_x_df.to_numpy()\n",
    "### read train y\n",
    "train_y_df=pd.read_parquet(f\"parquet/{miss_rate}/train_y.parquet\")\n",
    "y_train=train_y_df.to_numpy()\n",
    "\n",
    "# ## KNN Classfier trained on complete training data (no missing values)\n",
    "# neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "# neigh.fit(x_train, np.ravel(y_train,order='C'))\n",
    "    \n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = neigh.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on KNN: {train_accuracy}\")\n",
    "\n",
    "# ## XGB Classfier trained on complete training data (no missing values)\n",
    "# xgb_model=xgb.XGBClassifier(objective='binary:logistic')\n",
    "# xgb_model.fit(x_train,y_train)\n",
    "\n",
    "# # Make predictions on the training data\n",
    "# y_train_pred = xgb_model.predict(x_train)\n",
    "\n",
    "# # Calculate accuracy on the training data\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Train Accuracy on XGB: {train_accuracy}\")\n",
    "\n",
    "print('ACCURACY CALCULATION')\n",
    "\n",
    "##find acc for knn ffill\n",
    "predictions_knn_ffill = neigh.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill))\n",
    "print(\"Accuracy Score of KNN Classifier (Forward Fill): \")\n",
    "acc_knn_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_ffill)\n",
    "\n",
    "print(acc_knn_ffill)\n",
    "\n",
    "### find acc for knn bfill\n",
    "predictions_knn_bfill = neigh.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_knn_bfill))\n",
    "print(\"Accuracy Score of KNN Classifier: (Backward Fill)\")\n",
    "acc_knn_bfill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_knn_bfill)\n",
    "\n",
    "print(acc_knn_bfill)\n",
    "\n",
    "###find acc for xgboost ffill\n",
    "predictions_xgb_ffill=xgb_model.predict(full_test_set_ffill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill))\n",
    "print(\"Accuracy Score of XGB Classifier (Forward Fill): \")\n",
    "acc_xgb_ffill = accuracy_score(full_test_set_ffill.iloc[:, -1], predictions_xgb_ffill)\n",
    "\n",
    "print(acc_xgb_ffill)\n",
    "\n",
    "##find acc for knn bfill\n",
    "predictions_xgb_bfill=xgb_model.predict(full_test_set_bfill.iloc[:, :-1])\n",
    "print(classification_report(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill))\n",
    "print(\"Accuracy Score of XGB Classifier (Backward Fill): \")\n",
    "acc_xgb_bfill = accuracy_score(full_test_set_bfill.iloc[:, -1], predictions_xgb_bfill)\n",
    "\n",
    "\n",
    "print(acc_xgb_bfill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe18d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
